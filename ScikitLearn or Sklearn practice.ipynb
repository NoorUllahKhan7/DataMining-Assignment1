{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn workflow\n",
    "1. Getting the data ready\n",
    "2. choose the right model/estimator \n",
    "3. Fit the data\n",
    "4. Evaluate the model \n",
    "5. improve a model by tunning hyperparamteres\n",
    "6. Save and load a train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd\n",
    "#import scikit as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read csv file \n",
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data ready by sepearting labels and features\n",
    "#Seperating target column because it's y \n",
    "X = heart_disease.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "0        0   0     1  \n",
       "1        0   0     2  \n",
       "2        2   0     2  \n",
       "3        2   0     2  \n",
       "4        2   0     2  \n",
       "..     ...  ..   ...  \n",
       "298      1   0     3  \n",
       "299      1   0     3  \n",
       "300      1   2     3  \n",
       "301      1   1     3  \n",
       "302      1   1     2  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature set not including y column(ouput)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting y labels\n",
    "Y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "298    0\n",
       "299    0\n",
       "300    0\n",
       "301    0\n",
       "302    0\n",
       "Name: target, Length: 303, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting model clf stands for classifier random forest \n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train test split to prepare data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data ready\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "clf.fit(X_train,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using X test\n",
    "y_prd = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking model accuracy on training data \n",
    "clf.score(X_train,Y_train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.32786885245902"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking model accuracy on test data\n",
    "clf.score(X_test, Y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importin score metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.76      0.70      0.73        23\\n           1       0.82      0.87      0.85        38\\n\\n    accuracy                           0.80        61\\n   macro avg       0.79      0.78      0.79        61\\nweighted avg       0.80      0.80      0.80        61\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(Y_test, y_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  8],\n",
       "       [ 2, 28]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, y_prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.60655737704919"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, y_prd) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying value of estimator 10\n",
      "prediction score for 10 is 86.88524590163934\n",
      "Trying value of estimator 20\n",
      "prediction score for 20 is 83.60655737704919\n",
      "Trying value of estimator 30\n",
      "prediction score for 30 is 81.9672131147541\n",
      "Trying value of estimator 40\n",
      "prediction score for 40 is 85.24590163934425\n",
      "Trying value of estimator 50\n",
      "prediction score for 50 is 80.32786885245902\n",
      "Trying value of estimator 60\n",
      "prediction score for 60 is 80.32786885245902\n",
      "Trying value of estimator 70\n",
      "prediction score for 70 is 83.60655737704919\n",
      "Trying value of estimator 80\n",
      "prediction score for 80 is 85.24590163934425\n",
      "Trying value of estimator 90\n",
      "prediction score for 90 is 78.68852459016394\n"
     ]
    }
   ],
   "source": [
    "# Impoving model by using different hyperparameter\n",
    "for i in range(10,100, 10):\n",
    "    print(f\"Trying value of estimator {i}\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, Y_train)\n",
    "    print(f\"prediction score for {i} is {clf.score(X_test,Y_test) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load a model \n",
    "import pickle\n",
    "pickle.dump(clf, open(\"random_forest_classifier_trained_on_heart_disease\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing saved model\n",
    "import pickle\n",
    "\n",
    "model = pickle.load(open(\"random_forest_classifier_trained_on_heart_disease\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868852459016393"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting string values to numberic so to train our model on such data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "car_sales = pd.read_csv(\"data/car_slaes_missing_dropped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163322.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "810     BMW   Blue       163322.0    3.0  31666.0\n",
       "811  Toyota  Black        35820.0    4.0  32042.0\n",
       "812  Nissan   Blue        66604.0    4.0  31570.0\n",
       "813   Honda  White       215883.0    4.0   4001.0\n",
       "814  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[815 rows x 5 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.head(10)\n",
    "#Dropping extra column\n",
    "#car_sales = car_sales.drop(\"Unnamed: 0\", axis=1)\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating y variable and assigning label data\n",
    "\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "\n",
    "Y = car_sales[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      15323.0\n",
       "1      19943.0\n",
       "2      28343.0\n",
       "3      13434.0\n",
       "4      14043.0\n",
       "        ...   \n",
       "810    31666.0\n",
       "811    32042.0\n",
       "812    31570.0\n",
       "813     4001.0\n",
       "814    12732.0\n",
       "Name: Price, Length: 815, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Red</td>\n",
       "      <td>42652.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163453.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>131253.237895</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>51029.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>167421.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Green</td>\n",
       "      <td>17119.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>102303.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>199833.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>205592.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Red</td>\n",
       "      <td>96742.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Make Colour  Odometer (KM)  Doors\n",
       "0    Honda  White   35431.000000    4.0\n",
       "1      BMW   Blue  192714.000000    5.0\n",
       "2    Honda  White   84714.000000    4.0\n",
       "3   Toyota  White  154365.000000    4.0\n",
       "4   Nissan   Blue  181577.000000    3.0\n",
       "5    Honda    Red   42652.000000    4.0\n",
       "6   Toyota   Blue  163453.000000    4.0\n",
       "7    Honda  White  131253.237895    4.0\n",
       "8    Honda   Blue   51029.000000    4.0\n",
       "9   Nissan  White  167421.000000    4.0\n",
       "10  Nissan  Green   17119.000000    4.0\n",
       "11  Nissan  White  102303.000000    4.0\n",
       "12   Honda   Blue  199833.000000    4.0\n",
       "13  Toyota   Blue  205592.000000    4.0\n",
       "14  Toyota    Red   96742.000000    4.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(15\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing model named random forest regressor as it's a regression problem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiante random forest regressor \n",
    "clf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importin test train split to split our data into two sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting our data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Honda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-7e261c17d46b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# training our model on this data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mH:\\Latest data science courses\\My first project\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Latest data science courses\\My first project\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mH:\\Latest data science courses\\My first project\\env\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Honda'"
     ]
    }
   ],
   "source": [
    "# training our model on this data \n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model cannot be trained on this data because some of it's columns are in string format \n",
    "# so now we will change them to numberical format so that we can train our model \n",
    "\n",
    "# importing function for that purpose \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "\n",
    "# instantiating one hot encode\n",
    "one_hot = OneHotEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will now pass our one hot encoder and data to encode to out column transformer\n",
    "\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                 one_hot,\n",
    "                                 categorical_features)],\n",
    "                               remainder=\"passthrough\")\n",
    "# now fitting to our X variable\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   10   11        12\n",
       "0    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   35431.0\n",
       "1    1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  192714.0\n",
       "2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   84714.0\n",
       "3    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  154365.0\n",
       "4    0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  181577.0\n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
       "810  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  163322.0\n",
       "811  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   35820.0\n",
       "812  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0   66604.0\n",
       "813  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  215883.0\n",
       "814  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  248360.0\n",
       "\n",
       "[815 rows x 13 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting tranformed_X in to data frame\n",
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doors</th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doors  Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0      4.0         0           1            0            0             0   \n",
       "1      5.0         1           0            0            0             0   \n",
       "2      4.0         0           1            0            0             0   \n",
       "3      4.0         0           0            0            1             0   \n",
       "4      3.0         0           0            1            0             0   \n",
       "..     ...       ...         ...          ...          ...           ...   \n",
       "810    3.0         1           0            0            0             0   \n",
       "811    4.0         0           0            0            1             1   \n",
       "812    4.0         0           0            1            0             0   \n",
       "813    4.0         0           1            0            0             0   \n",
       "814    4.0         0           0            0            1             0   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  \n",
       "0              0             0           0             1  \n",
       "1              1             0           0             0  \n",
       "2              0             0           0             1  \n",
       "3              0             0           0             1  \n",
       "4              1             0           0             0  \n",
       "..           ...           ...         ...           ...  \n",
       "810            1             0           0             0  \n",
       "811            0             0           0             0  \n",
       "812            1             0           0             0  \n",
       "813            0             0           0             1  \n",
       "814            1             0           0             0  \n",
       "\n",
       "[815 rows x 10 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get a more breif view \n",
    "dummies = pd.get_dummies(car_sales[[\"Make\",\"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let refit/retrain our model \n",
    "np.random.seed(42)\n",
    "len(Y),len(transformed_X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(transformed_X, Y, test_size=0.2)\n",
    "#len(X_train) , len(Y_train)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30483684162728897"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's now fill our missing values in this part by first method.\n",
    "* Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Red</td>\n",
       "      <td>42652.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163453.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>130538.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>51029.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26683.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0\n",
       "5   Honda    Red        42652.0    4.0  23883.0\n",
       "6  Toyota   Blue       163453.0    4.0   8473.0\n",
       "7   Honda  White            NaN    4.0  20306.0\n",
       "8     NaN  White       130538.0    4.0   9374.0\n",
       "9   Honda   Blue        51029.0    4.0  26683.0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing pandas \n",
    "import pandas as pd\n",
    "\n",
    "# importing our data set with missing values\n",
    "\n",
    "car_sales_missing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows in our dataset\n",
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how much missing values are in each column \n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing all rows having price values missing because those rows having missing labels are useless\n",
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Red</td>\n",
       "      <td>42652.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163453.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>130538.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>51029.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26683.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0\n",
       "5   Honda    Red        42652.0    4.0  23883.0\n",
       "6  Toyota   Blue       163453.0    4.0   8473.0\n",
       "7   Honda  White            NaN    4.0  20306.0\n",
       "8     NaN  White       130538.0    4.0   9374.0\n",
       "9   Honda   Blue        51029.0    4.0  26683.0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating X and Y \n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "Y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors\n",
       "0   Honda  White        35431.0    4.0\n",
       "1     BMW   Blue       192714.0    5.0\n",
       "2   Honda  White        84714.0    4.0\n",
       "3  Toyota  White       154365.0    4.0\n",
       "4  Nissan   Blue       181577.0    3.0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15323.0\n",
       "1    19943.0\n",
       "2    28343.0\n",
       "3    13434.0\n",
       "4    14043.0\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values with pandas method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling make column \n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "#filling colour column \n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "#filling door column\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)\n",
    "\n",
    "#filling Odometer column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(),\n",
    "                                                                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Red</td>\n",
       "      <td>42652.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163453.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>130987.447894</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>missing</td>\n",
       "      <td>White</td>\n",
       "      <td>130538.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>51029.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26683.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Make Colour  Odometer (KM)  Doors    Price\n",
       "0    Honda  White   35431.000000    4.0  15323.0\n",
       "1      BMW   Blue  192714.000000    5.0  19943.0\n",
       "2    Honda  White   84714.000000    4.0  28343.0\n",
       "3   Toyota  White  154365.000000    4.0  13434.0\n",
       "4   Nissan   Blue  181577.000000    3.0  14043.0\n",
       "5    Honda    Red   42652.000000    4.0  23883.0\n",
       "6   Toyota   Blue  163453.000000    4.0   8473.0\n",
       "7    Honda  White  130987.447894    4.0  20306.0\n",
       "8  missing  White  130538.000000    4.0   9374.0\n",
       "9    Honda   Blue   51029.000000    4.0  26683.0"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check if we have any missing values remaining \n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into X and Y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "Y = car_sales[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert catagorical values to numerical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "catagorical_values = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                               one_hot,\n",
    "                               catagorical_values)],\n",
    "                               remainder=\"passthrough\")\n",
    "transformer_X = transformer.fit_transform(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will fill missing values using Skleran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import skearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will fill catagorical with missing and numerical with mean\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# define colums\n",
    "cat_feature = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create  an imputer to fill values\n",
    "X_transformed = ColumnTransformer([(\"cat_imputer\",cat_imputer,cat_feature),\n",
    "                                  (\"door_imputer\",door_imputer,door_feature),\n",
    "                                  (\"num_impurter\",num_imputer,num_features)],\n",
    "                             )\n",
    "filled_X = X_transformed.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Honda', 'White', 4.0, 35431.0],\n",
       "       ['BMW', 'Blue', 5.0, 192714.0],\n",
       "       ['Honda', 'White', 4.0, 84714.0],\n",
       "       ...,\n",
       "       ['Nissan', 'Blue', 4.0, 66604.0],\n",
       "       ['Honda', 'White', 4.0, 215883.0],\n",
       "       ['Toyota', 'Blue', 4.0, 248360.0]], dtype=object)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a data frame using fille_X\n",
    "car_sales_X_filled =  pd.DataFrame(filled_X, columns=[\"Make\",\"Colour\",\"Odometer (Km)\",\"Doors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (Km)</th>\n",
       "      <th>Doors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4</td>\n",
       "      <td>35431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>5</td>\n",
       "      <td>192714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4</td>\n",
       "      <td>84714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>4</td>\n",
       "      <td>154365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3</td>\n",
       "      <td>181577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>35820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>missing</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>155144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4</td>\n",
       "      <td>66604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>4</td>\n",
       "      <td>215883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4</td>\n",
       "      <td>248360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Make Colour Odometer (Km)   Doors\n",
       "0      Honda  White             4   35431\n",
       "1        BMW   Blue             5  192714\n",
       "2      Honda  White             4   84714\n",
       "3     Toyota  White             4  154365\n",
       "4     Nissan   Blue             3  181577\n",
       "..       ...    ...           ...     ...\n",
       "945   Toyota  Black             4   35820\n",
       "946  missing  White             3  155144\n",
       "947   Nissan   Blue             4   66604\n",
       "948    Honda  White             4  215883\n",
       "949   Toyota   Blue             4  248360\n",
       "\n",
       "[950 rows x 4 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_X_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (Km)    0\n",
       "Doors            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_X_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's implement a linear model on a boston dataset in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset from scikit-learn\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#let's convert this dataset into pandas dataset\n",
    "boston_data = pd.DataFrame(boston[\"data\"], columns=boston[\"feature_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data[\"target\"]= boston[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After consulting to scikit learn model map we will use ridge model\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will prepare our data and split into X and Y\n",
    "X = boston_data.drop(\"target\", axis=1)\n",
    "Y = boston_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test split function \n",
    "from  sklearn.model_selection import train_test_split\n",
    "# we will split data to test train split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now will fit the model \n",
    "model = Ridge()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.55593152168747"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, Y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.49390820917864"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now will use same dataset and fit it to random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor()\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.score(X_test, Y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so our accuracy had been improved by using random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we will now look at two function predict()  and predict_proba() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.807, 21.434, 20.823, 14.517, 31.3  ])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-264-6477bee352d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's train our regression model for our boston_data \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#let's seed so that our values remain same\n",
    "np.random.seed(42)\n",
    "\n",
    "# let's prepare our data\n",
    "X = boston_data.drop([\"target\"], axis=1)\n",
    "Y = boston_data[\"target\"]\n",
    "# let's split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# let's fit the model\n",
    "\n",
    "model = RandomForestRegressor().fit(X_train, Y_train)\n",
    "# Predicted by model\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual output\n",
    "Y_actual = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1226372549019623"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use a mertic calle mean square\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(Y_actual, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will use cross-validation to evaluate our predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83606557, 0.8852459 , 0.81967213, 0.81666667, 0.8       ])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing cross validations\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "\n",
    "# prepare data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "Y = heart_disease[\"target\"]\n",
    "\n",
    "#importing model and train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#splitting data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y , test_size=0.2)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "clf.score(X_test, Y_test)\n",
    "\n",
    "# let's use cross validatoi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#now we will call cross_val_score on this data\n",
    "\n",
    "cross_val_score(clf,X,Y,cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116939890710382"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take mean of cross_val_score using numpy\n",
    "np.mean(cross_val_score(clf,X,Y,cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now we will evaluate our model using Area under the curve or ROC/AUC metric so let's go\n",
    "\n",
    "* it's basically comparison between true positive or false positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import this roc_cruve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#make predictions with probabilities \n",
    "y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "# let's only use predictions for class = 1\n",
    "# so we will use numpy indexing to seperate this \n",
    "\n",
    "y_prob_pos = y_prob[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66, 0.83, 0.01, 0.95, 0.28, 0.58, 0.21, 0.5 , 0.65, 0.15])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate fpr(false positive rate), tpr(true postive rate) and thresholds\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_prob_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8790322580645162"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's calculate score using roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y_test, y_prob_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting a plot for roc curve so we will will define a function for that\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# now we will define a function to plot that cruve\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    #plot roc curve \n",
    "    plt.plot(fpr,tpr,color=\"darkblue\", label=\"ROC\")\n",
    "    #customizing the plot\n",
    "    plt.xlabel(\"false positive rate\")\n",
    "    plt.ylabel(\"true positive rate\")\n",
    "    plt.title(\"ROC plot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  we will use confusion matrix to evaluate our model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  8],\n",
       "       [ 6, 23]], dtype=int64)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_predics = clf.predict(X_test)\n",
    "confusion_matrix(y_predics, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual  labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted labels   0   1\n",
       "Actual  labels          \n",
       "0                 24   6\n",
       "1                  8  23"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we call use pandas cross tab function to visualise it\n",
    "pd.crosstab(Y_test,\n",
    "            y_predics ,\n",
    "            colnames=[\"Predicted labels\"],\n",
    "                                                   rownames=[\"Actual  labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: H:\\Latest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's install seaborn using jupyter notebook\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix}  seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c90a0d2fd0>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visulase it through sea born\n",
    "import seaborn as sns\n",
    "\n",
    "#set font \n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# create confusion matrix \n",
    "conf_mat= confusion_matrix(Y_test, y_predics)\n",
    "\n",
    "# create heat map using sea born\n",
    "\n",
    "sns.heatmap(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77        30\n",
      "           1       0.79      0.74      0.77        31\n",
      "\n",
      "    accuracy                           0.77        61\n",
      "   macro avg       0.77      0.77      0.77        61\n",
      "weighted avg       0.77      0.77      0.77        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's implement our last metric for classification models classification report \n",
    "from sklearn.metrics  import classification_report \n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will see  metrics applied to a regression model\n",
    "## * Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#importing MAE \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#import dataset\n",
    "car_sales  = pd.read_csv(\"data/car-sales.csv\")\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X  = car_sales.drop(\"Price\", axis = 1)\n",
    "Y = car_sales[\"Price\"]\n",
    "\n",
    "X_train, Xtest, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Toyota'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-352-9a3424afcdb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# implementing MAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Latest data science courses\\My first project\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Latest data science courses\\My first project\\env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mH:\\Latest data science courses\\My first project\\env\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Toyota'"
     ]
    }
   ],
   "source": [
    "# implementing MAE\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finally using the scoring parameter in cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83606557, 0.8852459 , 0.83606557, 0.8       , 0.75      ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing cross val score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Getting data ready \n",
    "\n",
    "heart_disease = pd.read_csv(\"data/heart-disease.csv\")\n",
    "\n",
    "# Preparing data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y , test_size=0.2)\n",
    "\n",
    "# seed so our result can be reproducible \n",
    "np.random.seed(42)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "#clf.score(X_test, Y_test)\n",
    "\n",
    "\n",
    "# let's use cross val\n",
    "\n",
    "cv = cross_val_score(clf, X, y, scoring=\"accuracy\" )\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214754098360656"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545454545454545"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's use a differenct metric let's say  we use recall \n",
    "cv_recall = cross_val_score(clf, X, y , scoring=\"recall\")\n",
    "cv_recall\n",
    "np.mean(cv_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78947368, 0.90625   , 0.83870968, 0.78787879, 0.77777778])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will use percision \n",
    "cv_prec = cross_val_score(clf, X, y , scoring=\"precision\")\n",
    "cv_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8200179854572893"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.850198536051878"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's try our last f1 metric\n",
    "cv_f1 = cross_val_score(clf, X, y, scoring=\"f1\")\n",
    "np.mean(cv_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOw let's do this for regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6157785876205734"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# now let's prepare data\n",
    "X = boston_data.drop(\"target\", axis=1)\n",
    "y = boston_data[\"target\"]\n",
    "\n",
    "\n",
    "# now let's split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# now let's fit our model \n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)\n",
    "\n",
    "\n",
    "# now let's try corss validation \n",
    "cv = cross_val_score(model, X, y)\n",
    "np.mean(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6127120708980884"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's try a differenct metric \n",
    "cv_r2 = cross_val_score(model, X, y, scoring=\"r2\")\n",
    "np.mean(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0464972432537367"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try mean absolute error(MAE)\n",
    "cv_mae = cross_val_score(model, X, y, scoring=\"neg_mean_absolute_error\")\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21.815890644767993"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try mean square error(MSE)\n",
    "cv_mae = cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\")\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will tune our hyperparameters by thre ways\n",
    "* by hand\n",
    "* by randomized search \n",
    "* Grid method\n",
    "\n",
    "\n",
    "\n",
    "`By Hand`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will do it by hand so let's do it\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check what are the hyperparameter it has\n",
    "\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing different metrics \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Now we will make a function to evaluate our Classification model on different metrics like precision, recall etc\n",
    "def evaluate_prd(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    metric_dict = { \"accuracy\" : round(accuracy,2),\n",
    "                   \"precision\" : round(precision,2),\n",
    "                   \"recall\" : round(recall,2),\n",
    "                   \"f1\" : round(f1,2)\n",
    "                  }\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f} %\")\n",
    "    print(f\"Precision: {precision }\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    \n",
    "    return metric_dict\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.22 %\n",
      "Precision: 0.8148148148148148\n",
      "Recall: 0.88\n",
      "F1: 0.8461538461538461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.81, 'recall': 0.88, 'f1': 0.85}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's prepare our data\n",
    "\n",
    "np.random.seed(42)\n",
    "#let's shuffle our data or randomize it\n",
    "\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "# let's seperate x and y \n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "#let make three sets training, validation and test set\n",
    "\n",
    "train_split = round(0.7 * len(heart_disease_shuffled))\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled))\n",
    "train_split\n",
    "X_train , Y_train = X[:train_split], y[:train_split]\n",
    "\n",
    "X_valid , Y_valid = X[train_split: valid_split], y[train_split:valid_split]\n",
    "X_test , Y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "# make basline preciction \n",
    "y_preds = clf.predict(X_valid)\n",
    "len(y_preds), len(Y_valid)\n",
    "evaluate_prd(Y_valid, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.44 %\n",
      "Precision: 0.8461538461538461\n",
      "Recall: 0.88\n",
      "F1: 0.8627450980392156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.84, 'precision': 0.85, 'recall': 0.88, 'f1': 0.86}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 2 \n",
    "#let's change our model parameters\n",
    "clf2 = RandomForestClassifier(n_estimators= 100)\n",
    "clf2.fit(X_train, Y_train)\n",
    "# make basline preciction \n",
    "y_preds = clf2.predict(X_valid)\n",
    "len(y_preds), len(Y_valid)\n",
    "evaluate_prd(Y_valid, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning usin randomized search CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   5.5s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   2.9s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   2.7s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   3.1s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   2.8s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   2.6s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   2.8s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   2.7s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   2.7s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   2.8s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   1.4s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   2.5s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   2.6s\n",
      "[CV] n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   2.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30, total=   1.5s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30, total=   1.4s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=30, total=   1.3s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=20, total=   0.2s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=5, total=   0.6s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   2.9s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   3.0s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   2.7s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   2.7s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=10, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100, n_jobs...\n",
       "                                                    random_state=None,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_depth': [None, 5, 10, 20, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 4, 6],\n",
       "                                        'n_estimators': [10, 100, 200, 500,\n",
       "                                                         1000, 1200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's import  randomized  serach cv\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Hyperparameters that we want to train\n",
    "grid = { \"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "         \"min_samples_split\": [2, 4, 6],\n",
    "         \"min_samples_leaf\":[1,2,4]\n",
    "    \n",
    "\n",
    "       }\n",
    "\n",
    "# Instantiate  random forest classifier\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# strup randomized serarch cv\n",
    "\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                       param_distributions=grid,\n",
    "                       n_iter=10, # no of models to try \n",
    "                       cv=5,\n",
    "                       verbose=2)\n",
    "#fit the model \n",
    "rs_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1200,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 10}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.61 %\n",
      "Precision: 0.8695652173913043\n",
      "Recall: 0.8\n",
      "F1: 0.8333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.83, 'precision': 0.87, 'recall': 0.8, 'f1': 0.83}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_clf_pred =rs_clf.predict(X_test)\n",
    "\n",
    "evaluate_prd(Y_test, rd_clf_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will save our trained model \n",
    "## There are two ways to do it\n",
    "\n",
    "1. using pickle\n",
    "2. joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pickle to save a trainede model\n",
    "import pickle as pkl\n",
    "\n",
    "# export/ save a model\n",
    "pkl.dump(rs_clf, open(\"random_forest_trained_model_1.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now importin our saved model again \n",
    "loaded_model = pkl.load(open(\"random_forest_trained_model_1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.61 %\n",
      "Precision: 0.8695652173913043\n",
      "Recall: 0.8\n",
      "F1: 0.8333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.83, 'precision': 0.87, 'recall': 0.8, 'f1': 0.83}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will use same model to predict\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "evaluate_prd(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`using joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing joblib\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_trained_model1.joblib']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(rs_clf,filename=\"random_forest_trained_model1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing model again\n",
    "loaded_mode = load(filename=\"random_forest_trained_model1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.61 %\n",
      "Precision: 0.8695652173913043\n",
      "Recall: 0.8\n",
      "F1: 0.8333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.83, 'precision': 0.87, 'recall': 0.8, 'f1': 0.83}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making predictions using this model\n",
    "y_pred = loaded_mode.predict(X_test)\n",
    "evaluate_prd(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's put it together all we have learn till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries for getting data read\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# libraries for modeling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# let's seeed to make our results reproducible\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# let's import and clean our data\n",
    "\n",
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "\n",
    "#let's remove rows with missing labels\n",
    "\n",
    "data.dropna(subset=[\"Price\"],inplace=True)\n",
    "\n",
    "#define different features and transformer pipelines\n",
    "catagorical_features = [\"Make\" , \"Colour\"]\n",
    "catagorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value= \"missing\") ),\n",
    "    ( \"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "door_features = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"constant\", fill_value= 4))])\n",
    "\n",
    "numerical_features = [\"Odometer (KM)\"]\n",
    "numerical_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "# Setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"cat\", catagorical_transformer, catagorical_features),\n",
    "                    (\"door\", door_transformer, door_features),\n",
    "                    (\"num\", numerical_transformer, numerical_features)\n",
    "                ])\n",
    "\n",
    "# creating a preprocessing and modeling pipleline\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                        (\"model\", RandomForestRegressor()) ])\n",
    "\n",
    "# split data\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "#len(X_train), len(X_test), len(Y_train), len(Y_test)\n",
    "\n",
    "#fit and score\n",
    "\n",
    "model.fit(X_train,Y_train);\n",
    "model.score(X_test, Y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   3.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   3.7s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   3.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   3.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   3.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   3.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   3.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.9s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   3.0s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   3.0s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   3.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   3.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   3.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.9s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.0s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.0s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.5s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value='missing',\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='constant',\n",
       "                                                                                                        verbo...\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'model__max_depth': [None, 5],\n",
       "                         'model__max_features': ['auto'],\n",
       "                         'model__min_samples_split': [2, 4],\n",
       "                         'model__n_estimators': [100, 1000],\n",
       "                         'preprocessor__num__imputer__strategy': ['mean',\n",
       "                                                                  'median']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using grid serach cv to improve our regression model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\":[\"mean\",\"median\"],\n",
    "    \"model__n_estimators\": [100,1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"auto\"],\n",
    "    \"model__min_samples_split\":[2,4]\n",
    "    \n",
    "    }\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3339554263158365"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so here our scikit learn section ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
